        Preparing the environment for use of requested stage ( Devel-2019a ).
     
        Preparing the environment for use of requested stage ( 2019a ).
     

Due to MODULEPATH changes, the following have been reloaded:
  1) CUDA/10.1.105     3) GCCcore/.8.3.0         5) binutils/.2.32
  2) GCC/8.3.0         4) MVAPICH2/2.3.2-GDR     6) nvidia/.418.87.00

The following have been reloaded with a version change:
  1) Stages/Devel-2019a => Stages/2019a

Lmod has detected the following error: These module(s) exist but cannot be
loaded as requested: "h5py/2.9.0-Python-3.6.8"
   Try: "module spider h5py/2.9.0-Python-3.6.8" to see how to load the
module(s).



[jrc0470:mpi_rank_0][MPIDI_CH3_Init] 

Please set LD_PRELOAD to the full path of libmpi.so of your MVAPICH2-GDR installation to avoid unexpected errors for GPU-based transfers

E.g. LD_PRELOAD=<PATH_TO_MVAPICH2_GDR_INSTALL>/lib64/libmpi.so

WARNING: Error in initializing MVAPICH2 ptmalloc library.Continuing without InfiniBand registration cache support.
2019-10-31 15:38:41.276423: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494155000 Hz
2019-10-31 15:38:41.276189: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494375000 Hz
2019-10-31 15:38:41.277022: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494155000 Hz
2019-10-31 15:38:41.275255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494260000 Hz
2019-10-31 15:38:41.277113: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494155000 Hz
2019-10-31 15:38:41.277276: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494155000 Hz
2019-10-31 15:38:41.278752: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x384b290 executing computations on platform Host. Devices:
2019-10-31 15:38:41.278779: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.278854: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x40e2fc0 executing computations on platform Host. Devices:
2019-10-31 15:38:41.278875: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.276289: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494375000 Hz
2019-10-31 15:38:41.276394: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494375000 Hz
2019-10-31 15:38:41.276816: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494375000 Hz
2019-10-31 15:38:41.278038: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4b39970 executing computations on platform Host. Devices:
2019-10-31 15:38:41.278062: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.278465: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3658b90 executing computations on platform Host. Devices:
2019-10-31 15:38:41.278491: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.279083: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4d73be0 executing computations on platform Host. Devices:
2019-10-31 15:38:41.278493: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4e56920 executing computations on platform Host. Devices:
2019-10-31 15:38:41.279106: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.278515: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.278581: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x35e66d0 executing computations on platform Host. Devices:
2019-10-31 15:38:41.278602: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.275261: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494260000 Hz
2019-10-31 15:38:41.279230: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3e185f0 executing computations on platform Host. Devices:
2019-10-31 15:38:41.275582: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494260000 Hz
2019-10-31 15:38:41.279251: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.275756: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494260000 Hz
2019-10-31 15:38:41.277002: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x34f5c20 executing computations on platform Host. Devices:
2019-10-31 15:38:41.277026: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.277519: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3e620e0 executing computations on platform Host. Devices:
2019-10-31 15:38:41.277542: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.277779: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52aeb10 executing computations on platform Host. Devices:
2019-10-31 15:38:41.277801: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:41.278128: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3a3e040 executing computations on platform Host. Devices:
2019-10-31 15:38:41.278150: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:38:42.361144: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x38a5fe0 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.361175: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.361182: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.361188: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.361194: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.363329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:86:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.363353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
2019-10-31 15:38:42.367433: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3e73340 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.367462: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.367469: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.367476: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.367481: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.368907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:06:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.368935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-10-31 15:38:42.369697: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4dce930 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.369721: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.369749: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.369755: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.369761: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.370662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:07:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.370707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
2019-10-31 15:38:42.375376: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x413dd10 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.375400: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.375408: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.375414: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.375420: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.375896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:87:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.375920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
2019-10-31 15:38:42.400150: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5309860 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.400181: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.400201: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.400207: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.400213: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.400908: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3550970 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.400938: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.400957: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.400963: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.400969: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.401912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:07:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.401954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
2019-10-31 15:38:42.402659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:87:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.402687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
2019-10-31 15:38:42.406003: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3a98d90 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.406032: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.406040: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.406046: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.406052: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.406761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:06:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.406786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-10-31 15:38:42.409975: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3ebce30 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.409999: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.410007: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.410012: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.410018: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.411322: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4b946c0 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.411356: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.411370: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.411376: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.411382: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.410708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:86:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.410733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
2019-10-31 15:38:42.413213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:86:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.413244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
2019-10-31 15:38:42.413230: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3641420 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.413266: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.413274: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.413287: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.413293: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.414316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:06:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.414343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-10-31 15:38:42.414432: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x36b38e0 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.414470: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.414482: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.414504: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.414516: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.415683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:87:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.415751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
2019-10-31 15:38:42.416072: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4eb1670 executing computations on platform CUDA. Devices:
2019-10-31 15:38:42.416104: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.416112: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.416118: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.416124: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:38:42.416648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:07:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:38:42.416675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
2019-10-31 15:38:42.713231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.713272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
2019-10-31 15:38:42.713279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
2019-10-31 15:38:42.713449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 2, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7)
2019-10-31 15:38:42.722929: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:38:42.727506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.727539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
2019-10-31 15:38:42.727545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
2019-10-31 15:38:42.727690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 3, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7)
2019-10-31 15:38:42.731355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.731385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-10-31 15:38:42.731404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-10-31 15:38:42.731509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.731532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
2019-10-31 15:38:42.731539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
2019-10-31 15:38:42.731584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2019-10-31 15:38:42.731700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
2019-10-31 15:38:42.733814: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:38:42.740878: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:38:42.750835: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:38:42.763383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.763422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
2019-10-31 15:38:42.763441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
2019-10-31 15:38:42.763641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
2019-10-31 15:38:42.763644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.763669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-10-31 15:38:42.763676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-10-31 15:38:42.763838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2019-10-31 15:38:42.769088: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:38:42.769231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.769265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
2019-10-31 15:38:42.769272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
2019-10-31 15:38:42.769446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 3, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7)
2019-10-31 15:38:42.769508: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:38:42.773714: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:38:42.775575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.775613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
2019-10-31 15:38:42.775620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
2019-10-31 15:38:42.775944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 2, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7)
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:38:42.781928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.781960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-10-31 15:38:42.781967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-10-31 15:38:42.782345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2019-10-31 15:38:42.787743: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:38:42.790891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.790913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
2019-10-31 15:38:42.790920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
2019-10-31 15:38:42.791101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 2, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7)
2019-10-31 15:38:42.801282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.801305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
2019-10-31 15:38:42.801312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
2019-10-31 15:38:42.801679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 3, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7)
2019-10-31 15:38:42.800614: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:38:42.804835: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:38:42.810441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:38:42.810469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
2019-10-31 15:38:42.810483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
2019-10-31 15:38:42.810844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:38:42.834830: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:38:42.847888: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-10-31 15:38:56.572080: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.594422: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.597028: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.612844: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.621047: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.625125: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.638233: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.646603: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.649002: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.652425: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.671874: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.673651: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.674261: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.698897: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.719132: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.735353: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.743819: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.745254: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.746162: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.758036: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.760468: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.769131: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.770045: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:56.783167: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:38:59.663016: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.668423: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.715416: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.756179: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.762244: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.810255: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.816695: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.868406: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.903388: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:38:59.933591: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:39:00.003514: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:39:00.020520: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:39:04.885236: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:05.336926: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:05.410519: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:05.530250: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:05.600520: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:06.321263: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:06.536535: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:06.610547: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:06.761160: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:06.794655: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:06.986736: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.058357: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.062444: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.082879: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.123237: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.134766: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.176886: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.203928: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.225472: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.245902: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.252113: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.256686: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.255897: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.264065: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.304417: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.314992: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.319694: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.334049: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.359076: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.365900: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.376757: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.406935: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.423083: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.433875: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.463200: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.511521: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.533483: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.534769: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.538796: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.538858: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.550890: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.581353: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.582818: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.598958: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.621294: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.668907: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.772200: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.831740: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.846490: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.955393: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.957901: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.963198: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:07.968508: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.034833: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.034733: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.038188: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.038560: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.041740: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.118308: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.153253: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.162721: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.169027: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.221490: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.237334: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.244725: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.246681: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.286693: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.319860: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.362750: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.490659: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:08.565295: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:39:21.008281: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.010107: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.010494: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.011289: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.012054: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.011176: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.012976: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.012994: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.013460: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.012503: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.014336: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.014922: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.014838: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.015859: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.016622: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.015342: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.016703: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.015432: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.015791: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.017863: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.019517: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.019538: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.018279: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:39:21.018702: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
