        Preparing the environment for use of requested stage ( Devel-2019a ).
     
        Preparing the environment for use of requested stage ( 2019a ).
     

Due to MODULEPATH changes, the following have been reloaded:
  1) CUDA/10.1.105     3) GCCcore/.8.3.0         5) binutils/.2.32
  2) GCC/8.3.0         4) MVAPICH2/2.3.2-GDR     6) nvidia/.418.87.00

The following have been reloaded with a version change:
  1) Stages/Devel-2019a => Stages/2019a

Lmod has detected the following error: These module(s) exist but cannot be
loaded as requested: "h5py/2.9.0-Python-3.6.8"
   Try: "module spider h5py/2.9.0-Python-3.6.8" to see how to load the
module(s).



[jrc0470:mpi_rank_0][MPIDI_CH3_Init] 

Please set LD_PRELOAD to the full path of libmpi.so of your MVAPICH2-GDR installation to avoid unexpected errors for GPU-based transfers

E.g. LD_PRELOAD=<PATH_TO_MVAPICH2_GDR_INSTALL>/lib64/libmpi.so

WARNING: Error in initializing MVAPICH2 ptmalloc library.Continuing without InfiniBand registration cache support.
2019-10-31 15:58:56.883364: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494375000 Hz
2019-10-31 15:58:56.884695: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494155000 Hz
2019-10-31 15:58:56.884749: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494155000 Hz
2019-10-31 15:58:56.882269: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494260000 Hz
2019-10-31 15:58:56.886469: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x46f6ba0 executing computations on platform Host. Devices:
2019-10-31 15:58:56.886493: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.886960: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x529de80 executing computations on platform Host. Devices:
2019-10-31 15:58:56.886982: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.883877: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494375000 Hz
2019-10-31 15:58:56.884546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494375000 Hz
2019-10-31 15:58:56.884756: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494375000 Hz
2019-10-31 15:58:56.885628: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3eaf280 executing computations on platform Host. Devices:
2019-10-31 15:58:56.885653: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.885689: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x37b1c20 executing computations on platform Host. Devices:
2019-10-31 15:58:56.885716: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.886419: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3912e60 executing computations on platform Host. Devices:
2019-10-31 15:58:56.886442: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.886631: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3ed27e0 executing computations on platform Host. Devices:
2019-10-31 15:58:56.886653: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.888887: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494155000 Hz
2019-10-31 15:58:56.889014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494155000 Hz
2019-10-31 15:58:56.882432: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494260000 Hz
2019-10-31 15:58:56.882789: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494260000 Hz
2019-10-31 15:58:56.884441: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x35ebc90 executing computations on platform Host. Devices:
2019-10-31 15:58:56.884465: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.884531: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494260000 Hz
2019-10-31 15:58:56.891652: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x365bad0 executing computations on platform Host. Devices:
2019-10-31 15:58:56.891692: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.884602: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4270a50 executing computations on platform Host. Devices:
2019-10-31 15:58:56.884625: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.891764: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5217c30 executing computations on platform Host. Devices:
2019-10-31 15:58:56.884673: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x37a6b80 executing computations on platform Host. Devices:
2019-10-31 15:58:56.891796: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.884696: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:56.887068: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x543bc80 executing computations on platform Host. Devices:
2019-10-31 15:58:56.887096: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 15:58:58.032122: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52f8bd0 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.032154: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.032162: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.032168: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.032174: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.033687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:87:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.033736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
2019-10-31 15:58:58.033003: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x42cb7a0 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.033034: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.033042: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.033048: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.033054: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.033182: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x36469e0 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.033208: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.033217: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.033223: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.033230: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.034210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:07:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.034236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
2019-10-31 15:58:58.034438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:87:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.034464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
2019-10-31 15:58:58.036937: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x36b6820 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.036967: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.036975: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.036981: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.037000: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.039097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:86:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.039158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
2019-10-31 15:58:58.039652: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x47518f0 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.039677: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.039684: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.039691: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.039696: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.040002: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5272980 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.040060: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.040071: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.040081: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.040090: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.040149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:06:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.040175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-10-31 15:58:58.040774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:07:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.040813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
2019-10-31 15:58:58.039709: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x54969d0 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.039741: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.039748: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.039755: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.039762: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.040868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:86:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.040905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
2019-10-31 15:58:58.041262: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x38018d0 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.041288: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.041296: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.041302: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.041308: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.041810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:06:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.041836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-10-31 15:58:58.054594: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x396dbb0 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.054625: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.054644: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.054650: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.054656: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.056002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:87:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.056029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
2019-10-31 15:58:58.059311: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x380c970 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.059347: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.059354: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.059359: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.059365: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.059679: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3f2d530 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.059708: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.059725: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.059732: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.059738: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.060520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:86:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.060575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
2019-10-31 15:58:58.060635: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3f09fd0 executing computations on platform CUDA. Devices:
2019-10-31 15:58:58.060683: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.060679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:06:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.060718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-10-31 15:58:58.060701: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.060738: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.060756: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7
2019-10-31 15:58:58.061252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:07:00.0
totalMemory: 11.17GiB freeMemory: 10.94GiB
2019-10-31 15:58:58.061273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
2019-10-31 15:58:58.393950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.393995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-10-31 15:58:58.394003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-10-31 15:58:58.394204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2019-10-31 15:58:58.403095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.403132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
2019-10-31 15:58:58.403139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
2019-10-31 15:58:58.403315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
2019-10-31 15:58:58.405325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.405366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
2019-10-31 15:58:58.405373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
2019-10-31 15:58:58.405550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 2, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7)
2019-10-31 15:58:58.405915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.405937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
2019-10-31 15:58:58.405944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
2019-10-31 15:58:58.406092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 2, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7)
2019-10-31 15:58:58.407946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.407969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
2019-10-31 15:58:58.407975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
2019-10-31 15:58:58.408124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
2019-10-31 15:58:58.408954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.408990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
2019-10-31 15:58:58.409008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
2019-10-31 15:58:58.409192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 3, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7)
2019-10-31 15:58:58.410242: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:58:58.414530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.414552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-10-31 15:58:58.414570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-10-31 15:58:58.414763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2019-10-31 15:58:58.412216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.412247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
2019-10-31 15:58:58.412254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
2019-10-31 15:58:58.412446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7)
2019-10-31 15:58:58.415548: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:58:58.415953: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:58:58.413944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.413966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
2019-10-31 15:58:58.413972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
2019-10-31 15:58:58.414151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 2, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7)
2019-10-31 15:58:58.417371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.417399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
2019-10-31 15:58:58.417418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
2019-10-31 15:58:58.417603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 3, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7)
2019-10-31 15:58:58.419517: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:58:58.419787: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:58:58.420279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.420311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-10-31 15:58:58.420318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-10-31 15:58:58.420488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7)
2019-10-31 15:58:58.421848: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:58:58.420566: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-10-31 15:58:58.422387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 15:58:58.422411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
2019-10-31 15:58:58.422418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
2019-10-31 15:58:58.422576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10591 MB memory) -> physical GPU (device: 3, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7)
2019-10-31 15:58:58.424692: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:58:58.434790: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:58:58.440827: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:58:58.443590: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-10-31 15:58:58.447811: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /usr/local/software/jureca/Stages/2019a/software/Horovod/0.16.2-gmvapich2c-2019a-GDR-GPU-Python-3.6.8/lib/python3.6/site-packages/horovod-0.16.2-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:81: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-10-31 15:59:12.192124: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.199067: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.214312: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.226863: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.263028: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.263431: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.291189: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.288821: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.290753: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.312694: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.315342: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.316309: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.321006: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.323940: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.342483: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.340868: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.345789: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.347762: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.353345: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.359921: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.380532: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.385271: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.464598: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:12.491495: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:15.129697: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.274924: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.306991: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.331082: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.373766: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.417761: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.501842: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.541516: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.547361: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.601722: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.630367: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:15.641431: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10 locally
2019-10-31 15:59:21.420226: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:21.691954: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.143568: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.149353: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.168190: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.225792: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.352654: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.426263: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.599282: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.608355: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.628311: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.632602: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.687632: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.712632: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.817844: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.843780: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.885999: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.894568: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.921247: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.938503: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:22.937656: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.056028: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.060267: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.078598: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.114788: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.137122: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.150716: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.149242: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.230523: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.265195: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.269697: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.338743: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.339983: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.355029: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.387734: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.460927: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.508833: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.565345: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.580641: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.582503: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.609109: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.636808: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.649422: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.688767: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.687985: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.702459: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.755267: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.766252: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.772399: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.811855: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.816724: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.823357: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.888042: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.44GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.892528: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.891665: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:23.966378: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:24.014736: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:24.089285: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-31 15:59:36.433082: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.434828: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.435924: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.436095: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.436271: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.437556: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.437706: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.438312: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.436291: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.436455: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.438718: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.438876: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.439156: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.440559: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.441302: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.439164: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.439332: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.441566: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.440404: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.441925: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.444867: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.443288: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.444852: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-10-31 15:59:36.447807: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
