{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib.transforms import Affine2D\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/p/project/deepacf/deeprain/video_prediction_shared_folder/models/\"+ \\\n",
    "       \"era5-Y2010toY2222M01to12-160x128-2970N1500W-T2_MSL_gph500/convLSTM/\"\n",
    "fname_timing_train = \"/timing_training_time.pkl\"\n",
    "fname_timing_total = \"/timing_total_time.pkl\"\n",
    "\n",
    "fname_timing_iter = \"timing_per_iteration_time.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some auxiliary functions\n",
    "def orderOfMagnitude(number):\n",
    "    return np.floor(np.log(number, 10))\n",
    "\n",
    "def total_times(infile):\n",
    "    with open(infile,'rb') as tfile:\n",
    "        #print(\"Opening pickle time: '{0}'\".format(infile))\n",
    "        total_time_sec = pickle.load(tfile)\n",
    "    return np.asarray(total_time_sec/60)\n",
    "\n",
    "def log_total_times(infile):\n",
    "    total_time_min = total_times(infile)\n",
    "    return np.log(total_time_min)\n",
    "\n",
    "\n",
    "def get_time_dict(base, wildcardspec, tfilename, gpu_id_str=\"gpu\", llog = False):\n",
    "    time_dict = {}\n",
    "    flist_hpc = sorted(glob.glob(base + wildcardspec))\n",
    "    wrapper = total_times\n",
    "    if llog: wrapper = log_total_times\n",
    "    for tfile in flist_hpc: \n",
    "        ngpus = get_ngpus(tfile, gpu_id_str)\n",
    "        time_dict[\"{0:d} GPU(s)\".format(ngpus)] = wrapper(tfile + tfilename)\n",
    "    return time_dict\n",
    "\n",
    "def get_ngpus(fname, search_str, max_order=3):\n",
    "    \"\"\"\n",
    "    Tries to get numbers in the vicinty of search_str which is supposed to be a substring in fname.\n",
    "    First seaches for numbers right before the occurence of search_str, then afterwards.\n",
    "    :param fname: file name from which number should be inferred\n",
    "    :param search_str: seach string for which number identification is considered to be possible\n",
    "    :param max_order: maximum order of retrieved number (default: 3 -> maximum number is 999 then)\n",
    "    :return num_int: integer of number in the vicintity of search string. \n",
    "    \"\"\"\n",
    "    \n",
    "    ind_gpu_info = fname.lower().find(search_str)\n",
    "    if ind_gpu_info == -1:\n",
    "        raise ValueError(\"Unable to find search string '{0}' in file name '{1}'\".format(search_str, fname))\n",
    "    \n",
    "    # init loops\n",
    "    fname_len = len(fname)\n",
    "    success, flag = False, True\n",
    "    indm = 1\n",
    "    ind_sm, ind_sp = 0, 0\n",
    "\n",
    "    # check occurence of numbers in front of search string\n",
    "    while indm < max_order and flag:\n",
    "        if ind_gpu_info - indm > 0:\n",
    "            if fname[ind_gpu_info - indm].isnumeric():\n",
    "                ind_sm += 1\n",
    "                success = True\n",
    "            else:\n",
    "                flag = False\n",
    "        else:\n",
    "            flag = False\n",
    "        indm += 1\n",
    "  \n",
    "\n",
    "    if not success: # check occurence of numbers after search string\n",
    "        ind_gpu_info = ind_gpu_info + len(search_str)\n",
    "        flag = True\n",
    "        indm = 0\n",
    "        while indm < max_order and flag: \n",
    "            if ind_gpu_info + indm < fname_len:\n",
    "                if fname[ind_gpu_info + indm].isnumeric():\n",
    "                    ind_sp += 1\n",
    "                    success = True\n",
    "                else:\n",
    "                    flag = False\n",
    "            else:\n",
    "                flag = False\n",
    "            indm += 1\n",
    "            \n",
    "        if success:\n",
    "            return(int(fname[ind_gpu_info:ind_gpu_info+ind_sp]))\n",
    "        else:\n",
    "            raise ValueError(\"Search string found in fname, but unable to infer number of GPUs.\")\n",
    "\n",
    "    else:\n",
    "        return(int(fname[ind_gpu_info-ind_sm:ind_gpu_info]))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total computation with 16 GPU(s): 152.50984706878663\n",
      "Total computation with 32 GPU(s): 81.80640578667322\n",
      "Total computation with 4 GPU(s): 554.5182513117791\n",
      "Total computation with 64 GPU(s): 45.01537701288859\n",
      "Total computation with 8 GPU(s): 287.91878341039023\n"
     ]
    }
   ],
   "source": [
    "# Juwels\n",
    "wildcard_juwels = '20210115T135325_langguth1_test_venv_juwels_container*old'\n",
    "total_time_min_juwels = get_time_dict(base, wildcard_juwels, fname_timing_total, \"gpus\")\n",
    "training_time_min_juwels = get_time_dict(base, wildcard_juwels, fname_timing_train, \"gpus\")\n",
    "for key in training_time_min_juwels.keys():\n",
    "    print(\"Total computation with {0}: {1}\".format(key, training_time_min_juwels[key]))\n",
    "\n",
    "overhead_time_juwels = {}\n",
    "for key in training_time_min_juwels.keys() & total_time_min_juwels.keys():\n",
    "    overhead_time_juwels[key] = total_time_min_juwels[key] - training_time_min_juwels[key]\n",
    "    \n",
    "#print('Juwels total time in minutes', get_time_d)\n",
    "#print('Juwels total training time in minutes', training_time_min_juwels)\n",
    "#overhead_time_juwels = np.array(total_time_min_juwels) - np.array(training_time_min_juwels)\n",
    "#print('Juwels overhead time in minutes', overhead_time_juwels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total computation with 1 GPU(s): 566.7376739541689\n",
      "Total computation with 4 GPU(s): 159.4931242307027\n",
      "Total computation with 8 GPU(s): 92.15467914342881\n",
      "Total computation with 16 GPU(s): 46.11619712909063\n",
      "Total computation with 32 GPU(s): 33.09077355464299\n",
      "Total computation with 64 GPU(s): 23.24405464331309\n"
     ]
    }
   ],
   "source": [
    "# Juwels booster\n",
    "wildcard_booster = '2020*gong1_booster_gpu*'\n",
    "total_time_min_booster = get_time_dict(base, wildcard_booster, fname_timing_total)\n",
    "training_time_min_booster = get_time_dict(base, wildcard_booster, fname_timing_train)\n",
    "for key in training_time_min_booster.keys():\n",
    "    print(\"Total computation with {0}: {1}\".format(key, training_time_min_booster[key]))\n",
    "\n",
    "#print('Juwels Booster total time in minutes', list_times(base, wildcard_booster, filename_timing_total))\n",
    "#print('Juwels Booster total training time in minutes', list_times(base, wildcard_booster, filename_timing_train))\n",
    "overhead_time_booster = {}\n",
    "for key in training_time_min_booster.keys() & total_time_min_booster.keys():\n",
    "    overhead_time_booster[key] = total_time_min_booster[key] - training_time_min_booster[key]\n",
    "#print('Juwels overhead time in minutes', overhead_time_booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_per_iteration_mean_std(infile):\n",
    "    with open(infile, 'rb') as tfile:\n",
    "        time_per_iteration_list = pickle.load(tfile) \n",
    "        \n",
    "    time_per_iteration = np.array(time_per_iteration_list)\n",
    "    return np.mean(time_per_iteration), np.std(time_per_iteration)\n",
    "\n",
    "def iter_stat(base, wildcardspec, gpu_id_str=\"gpu\"):\n",
    "    stat_iter_dict = {}\n",
    "    flist_hpc = sorted(glob.glob(base + wildcardspec))\n",
    "    for tdir in flist_hpc: \n",
    "        ngpus = get_ngpus(tdir, gpu_id_str)\n",
    "        ftname = os.path.join(tdir, fname_timing_iter)\n",
    "        mean_loc, std_loc = time_per_iteration_mean_std(ftname)\n",
    "        stat_iter_dict[\"{0:d} GPU(s)\".format(ngpus)] = {\"mean\": mean_loc , \"std\": std_loc}\n",
    "    return stat_iter_dict\n",
    "\n",
    "def time_per_iteration_all(infile):\n",
    "    with open(infile,'rb') as tfile:\n",
    "        time_per_iteration_list = pickle.load(tfile)\n",
    "    return np.asarray(time_per_iteration_list)\n",
    "\n",
    "def all_iter(base, wildcardspec, gpu_id_str=\"gpu\"):\n",
    "    iter_dict = {}\n",
    "    flist_hpc = sorted(glob.glob(base + wildcardspec))\n",
    "    for tdir in flist_hpc: \n",
    "        ngpus = get_ngpus(tdir, gpu_id_str)\n",
    "        ftname = os.path.join(tdir, fname_timing_iter)\n",
    "        iter_dict[\"{0:d} GPU(s)\".format(ngpus)] = time_per_iteration_all(ftname)\n",
    "    return iter_dict    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUWELS (0.6151515198034729, 0.20104178037750603)\n",
      "Booster (0.3521572324468615, 0.3656996619706779)\n"
     ]
    }
   ],
   "source": [
    "# Juwels\n",
    "print('JUWELS', time_per_iteration_mean_std('/p/project/deepacf/deeprain/video_prediction_shared_folder/models/era5-Y2010toY2222M01to12-160x128-2970N1500W-T2_MSL_gph500/convLSTM/20201210T140958_stadtler1_comparison_1node_1gpu/timing_per_iteration_time.pkl'))\n",
    "# Booster\n",
    "print('Booster', time_per_iteration_mean_std('/p/project/deepacf/deeprain/video_prediction_shared_folder/models/era5-Y2010toY2222M01to12-160x128-2970N1500W-T2_MSL_gph500/convLSTM/20201210T141910_gong1_booster_gpu1/timing_per_iteration_time.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juwels mean and standart deviation {'16 GPU(s)': {'mean': 0.8209993402058342, 'std': 0.2627643291319852}, '32 GPU(s)': {'mean': 0.8590118098249986, 'std': 0.4078450977768068}, '4 GPU(s)': {'mean': 0.7445914211655112, 'std': 0.13789611351045}, '64 GPU(s)': {'mean': 0.9353915504630987, 'std': 0.6640973670265782}, '8 GPU(s)': {'mean': 0.7804724221628322, 'std': 0.21824334555299446}}\n"
     ]
    }
   ],
   "source": [
    "# Juwels\n",
    "print('Juwels mean and standart deviation',iter_stat(base, wildcard_juwels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booster mean and standart deviation {'1 GPU(s)': {'mean': 0.3521572324468615, 'std': 0.3656996619706779}, '4 GPU(s)': {'mean': 0.41844419631014446, 'std': 0.5273198599590724}, '8 GPU(s)': {'mean': 0.48867375665101026, 'std': 0.4378652997442439}, '16 GPU(s)': {'mean': 0.4786909431320202, 'std': 0.49638173862734053}, '32 GPU(s)': {'mean': 0.6439339113469129, 'std': 1.4395666886291258}, '64 GPU(s)': {'mean': 0.8176603168024377, 'std': 2.1044189535471185}}\n"
     ]
    }
   ],
   "source": [
    "# Booster\n",
    "print('Booster mean and standart deviation',iter_stat(base, wildcard_booster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "# Bar plot of total time and training time --> overhead time\n",
    "\n",
    "# dictionaries with the total times\n",
    "tot_time_juwels_dict = get_time_dict(base, wildcard_juwels, fname_timing_total)\n",
    "tot_time_booster_dict= get_time_dict(base, wildcard_booster, fname_timing_total)\n",
    "\n",
    "# dictionaries with the training times\n",
    "train_time_juwels_dict = get_time_dict(base, wildcard_juwels, fname_timing_train)\n",
    "train_time_booster_dict = get_time_dict(base, wildcard_booster, fname_timing_train)\n",
    "\n",
    "# get sorted arrays\n",
    "# Note: The times for Juwels are divided by 2, since the experiments have been performed with an epoch number of 20\n",
    "#       instead of 10 (as Bing and Scarlet did)\n",
    "ngpus_sort = sorted([int(ngpu.split()[0]) for ngpu in tot_time_juwels_dict.keys()])\n",
    "nexps = len(ngpus_sort)\n",
    "tot_time_juwels = np.array([tot_time_juwels_dict[\"{0:d} GPU(s)\".format(key)] for key in ngpus_sort])/2.\n",
    "tot_time_booster = np.array([tot_time_booster_dict[\"{0:d} GPU(s)\".format(key)] for key in ngpus_sort])\n",
    "\n",
    "train_time_juwels = np.array([train_time_juwels_dict[\"{0:d} GPU(s)\".format(key)] for key in ngpus_sort])/2.\n",
    "train_time_booster = np.array([train_time_booster_dict[\"{0:d} GPU(s)\".format(key)] for key in ngpus_sort])\n",
    "\n",
    "overhead_juwels = tot_time_juwels - train_time_juwels \n",
    "overhead_booster= tot_time_booster - train_time_booster\n",
    "\n",
    "names = [\"Juwels\", \"Juwels Booster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400.0\n",
      "278.0\n",
      "100.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "plot_computation_times(tot_time_juwels, tot_time_booster, labels, [\"Juwels\", \"Juwels Booster\"], \\\n",
    "                       \"./total_computation_time\", log_yvals=False)\n",
    "\n",
    "plot_computation_times(overhead_juwels, overhead_booster, labels, [\"Juwels\", \"Juwels Booster\"], \\\n",
    "                       \"./overhead_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels)\n",
    "#raise ValueError(\"Stop!\")\n",
    "#x = np.arange(len(labels))  # the label locations\n",
    "#width = 0.35  # the width of the bars\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#rects1 = ax.bar(x - width/2, np.round(tot_time_juwels, 2), width, label='Juwels')\n",
    "#rects2 = ax.bar(x + width/2, np.round(tot_time_booster, 2), width, label='Booster')\n",
    "\n",
    "def plot_computation_times(times1, times2, ngpus, names, plt_fname, log_yvals = False):\n",
    "    \n",
    "    nlabels = len(ngpus)\n",
    "    x_pos = np.arange(nlabels)\n",
    "    \n",
    "    bar_width = 0.35\n",
    "    ytitle = \"Time\"\n",
    "    ymax = np.ceil(np.maximum(np.max(times1)/100. + 0.5, np.max(times2)/100. + 0.5))*100.\n",
    "    print(ymax)    \n",
    "    if log_yvals: \n",
    "        times1, times2 = np.log(times1), np.log(times2)\n",
    "        ytitle = \"LOG(Time) [min]\"\n",
    "        ymax = np.ceil(np.maximum(np.max(times1)+0.5, np.max(times2) + 0.5))\n",
    "    \n",
    "    # create plot object\n",
    "    fig, ax = plt.subplots()\n",
    "    # create data bars\n",
    "    rects1 = ax.bar(x_pos - bar_width/2, np.round(times1, 2), bar_width, label=names[0])\n",
    "    rects2 = ax.bar(x_pos + bar_width/2, np.round(times2, 2), bar_width, label=names[1])\n",
    "    # customize plot appearance\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel(ytitle)\n",
    "    ax.set_title('Comparison {0} and {1} with convLSTM model'.format(*names))\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlabel('# GPUs')\n",
    "    print(np.ceil(np.maximum(np.max(times1)+0.5, np.max(times2) + 0.5)))\n",
    "    ax.set_ylim(0., ymax)\n",
    "    ax.legend()\n",
    "                \n",
    "    # add labels\n",
    "    autolabel(ax, rects1)\n",
    "    autolabel(ax, rects2)\n",
    "    plt.savefig(plt_fname+\".png\")\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def autolabel(ax, rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean + std \n",
    "# Juwels\n",
    "dict_stat_juwels = iter_stat(base, wildcard_juwels, gpu_id_str=\"gpu\")\n",
    "#print(dict_stat_juwels)\n",
    "iter_mean_juwels = np.array([dict_stat_juwels[\"{0:d} GPU(s)\".format(key)][\"mean\"] for key in labels])\n",
    "iter_std_juwels = np.array([dict_stat_juwels[\"{0:d} GPU(s)\".format(key)][\"std\"] for key in labels])\n",
    "\n",
    "dict_stat_booster = iter_stat(base, wildcard_booster, gpu_id_str=\"gpu\")\n",
    "iter_mean_booster = np.array([dict_stat_booster[\"{0:d} GPU(s)\".format(key)][\"mean\"] for key in labels])\n",
    "iter_std_booster = np.array([dict_stat_booster[\"{0:d} GPU(s)\".format(key)][\"std\"] for key in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21225,)\n"
     ]
    }
   ],
   "source": [
    "iter_time_juwels = all_iter(base, wildcard_juwels)\n",
    "iter_time_booster= all_iter(base, wildcard_booster)\n",
    "\n",
    "max_iter_juwels = np.shape(iter_time_booster[\"{0:d} GPU(s)\".format(labels[0])])[0]\n",
    "max_iter_booster = np.shape(iter_time_booster[\"{0:d} GPU(s)\".format(labels[0])])[0]\n",
    "\n",
    "arr_iter_juwels = np.full((nexps, max_iter_juwels), np.nan)\n",
    "arr_iter_booster= np.full((nexps, max_iter_booster), np.nan)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot instead of errorbar plot\n",
    "# Juwels\n",
    "#data_juwels = list_time_per_iteration_all_runs(base, wildcard_juwels)\n",
    "data_juwels = all_iter(base, wildcard_juwels, gpu_id_str=\"gpu\")\n",
    "# Booster\n",
    "#data_booster = list_time_per_iteration_all_runs(base, wildcard_booster)\n",
    "data_booster = all_iter(base, wildcard_booster, gpu_id_str=\"gpu\")\n",
    "def simple_boxplot(time_per_iteration_data, title):\n",
    "    # Multiple box plots on one Axes\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(title)\n",
    "    ax.boxplot(time_per_iteration_data, showfliers=False) # Outliers for initialization are disturbing \n",
    "    plt.xticks([1, 2, 3, 4, 5 ,6], ['1', '4', '8', '16', '32', '64'])\n",
    "    #plt.savefig('boxplot_'+title)\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886\n",
      "64.08639097213745\n",
      "31.232596397399902\n",
      "(1326,)\n",
      "***********\n",
      "2100\n",
      "4.405388832092285\n",
      "29.095214366912842\n",
      "(2653,)\n",
      "***********\n",
      "36981\n",
      "7.751298189163208\n",
      "26.409477949142456\n",
      "(42450,)\n",
      "***********\n",
      "3843\n",
      "66.00082683563232\n",
      "29.385547637939453\n",
      "(21225,)\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(data_booster[\"64 GPU(s)\"]))\n",
    "print(np.max(data_booster[\"64 GPU(s)\"]))\n",
    "print(data_booster[\"64 GPU(s)\"][0])\n",
    "print(np.shape(data_booster[\"64 GPU(s)\"]))\n",
    "print(\"***********\")\n",
    "\n",
    "print(np.argmax(data_juwels[\"64 GPU(s)\"][1::]))\n",
    "print(np.max(data_juwels[\"64 GPU(s)\"][1::]))\n",
    "print(data_juwels[\"64 GPU(s)\"][0])\n",
    "print(np.shape(data_juwels[\"64 GPU(s)\"]))\n",
    "print(\"***********\")\n",
    "\n",
    "print(np.argmax(data_juwels[\"4 GPU(s)\"][1::]))\n",
    "print(np.max(data_juwels[\"4 GPU(s)\"][1::]))\n",
    "print(data_juwels[\"4 GPU(s)\"][0])\n",
    "print(np.shape(data_juwels[\"4 GPU(s)\"]))\n",
    " \n",
    "print(\"***********\")\n",
    "print(np.argmax(data_booster[\"4 GPU(s)\"][1::]))\n",
    "print(np.max(data_booster[\"4 GPU(s)\"][1::]))\n",
    "print(data_booster[\"4 GPU(s)\"][0])\n",
    "print(np.shape(data_booster[\"4 GPU(s)\"]))\n",
    "\n",
    "#simple_boxplot(data_juwels, 'Juwels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_boxplot(data_booster, 'Booster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try more fancy box plot \n",
    "def more_fancy_boxplot(time_per_iteration_data1, time_per_iteration_data2, ngpu_list, title):\n",
    "    nexps = len(ngpu_list)\n",
    "    # Shuffle data: EXPECT JUWELS FIRST FOR THE LEGEND! NOT GENERIC!\n",
    "    data = []\n",
    "    for i in np.arange(nexps):\n",
    "        data.append(time_per_iteration_data1[\"{0} GPU(s)\".format(ngpu_list[i])])\n",
    "        data.append(time_per_iteration_data2[\"{0} GPU(s)\".format(ngpu_list[i])])\n",
    "     \n",
    "    # trick to get list with duplicated entries\n",
    "    xlabels = [val for val in ngpu_list for _ in (0, 1)]\n",
    "\n",
    "    # Multiple box plots on one Axes\n",
    "    #fig, ax = plt.subplots()\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    ax = plt.axes([0.1, 0.15, 0.75, 0.75])   \n",
    "    \n",
    "    ax.set_title(title)\n",
    "    bp = ax.boxplot(data, notch=0, sym='+', vert=1, whis=1.5, showfliers=False) # Outliers for initialization are disturbing\n",
    "    plt.xticks(np.arange(1, nexps*2 +1), xlabels)\n",
    "    ax.set_xlabel('# GPUs')\n",
    "    ax.set_ylabel('Seconds')\n",
    "    \n",
    "    # Reference: https://matplotlib.org/3.1.1/gallery/statistics/boxplot_demo.html \n",
    "    box_colors = ['darkkhaki', 'royalblue']\n",
    "    num_boxes = len(data)\n",
    "    medians = np.empty(num_boxes)\n",
    "    for i in range(num_boxes):\n",
    "        box = bp['boxes'][i]\n",
    "        boxX = []\n",
    "        boxY = []\n",
    "        for j in range(5):\n",
    "            boxX.append(box.get_xdata()[j])\n",
    "            boxY.append(box.get_ydata()[j])\n",
    "        box_coords = np.column_stack([boxX, boxY])\n",
    "        # Alternate between Dark Khaki and Royal Blue\n",
    "        ax.add_patch(Polygon(box_coords, facecolor=box_colors[i % 2]))\n",
    "        # Now draw the median lines back over what we just filled in\n",
    "        med = bp['medians'][i]\n",
    "        medianX = []\n",
    "        medianY = []\n",
    "        for j in range(2):\n",
    "            medianX.append(med.get_xdata()[j])\n",
    "            medianY.append(med.get_ydata()[j])\n",
    "            ax.plot(medianX, medianY, 'k')\n",
    "        medians[i] = medianY[0]\n",
    "        # Finally, overplot the sample averages, with horizontal alignment\n",
    "        # in the center of each box\n",
    "        ax.plot(np.average(med.get_xdata()), np.average(data[i]),\n",
    "                color='w', marker='*', markeredgecolor='k')\n",
    "    \n",
    "    # Finally, add a basic legend\n",
    "    fig.text(0.9, 0.15, 'Juwels',\n",
    "             backgroundcolor=box_colors[0], color='black', weight='roman',\n",
    "             size='small')\n",
    "    fig.text(0.9, 0.09, 'Booster',\n",
    "             backgroundcolor=box_colors[1],\n",
    "             color='white', weight='roman', size='small')\n",
    "    #fig.text(0.90, 0.015, '*', color='white', backgroundcolor='silver',\n",
    "    #         weight='roman', size='medium')\n",
    "    fig.text(0.9, 0.03, '* Mean', color='white', backgroundcolor='silver',\n",
    "             weight='roman', size='small')\n",
    "\n",
    "    \n",
    "    plt.savefig('fancy_boxplot_'+title.replace(' ', '_'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_fancy_boxplot(data_juwels, data_booster, ngpus_sort, 'Time needed to iterate one step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist_hpc1 = sorted(glob.glob(base + wildcard_juwels))\n",
    "flist_hpc2 = sorted(glob.glob(base + wildcard_booster))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "print(get_ngpus(flist_hpc1[2], \"gpu\"))\n",
    "print(get_ngpus(flist_hpc1[0], \"gpu\"))\n",
    "\n",
    "print(get_ngpus(flist_hpc2[2], \"gpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
